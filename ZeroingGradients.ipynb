{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEqv28yvO7LEMK0Lqubvsg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renan-Domingues/PyTorchRecipes/blob/main/ZeroingGradients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zeroing out Gradients in Pytorch\n",
        "\n",
        "By defeult gradients are acumulate, not overwritten.\n",
        "So it's beneficial to zero them when buiding a neural network"
      ],
      "metadata": {
        "id": "Bfp3nLVua2rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Gradient descent is the process of minimizing our loss.\n",
        "\n",
        "In the training loop we have to zero the gradient so it dosen't acumulate in every epoch"
      ],
      "metadata": {
        "id": "g3uQoo3PbL90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps\n",
        "\n",
        "1. Import all necessary libraries for loading our data\n",
        "2. Load and normalize the dataset\n",
        "3. Build the neural network\n",
        "4. Define the loss function\n",
        "5. Zero the gradients while training the network"
      ],
      "metadata": {
        "id": "bfAfih9hbqRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import necessary libraries for loading our data"
      ],
      "metadata": {
        "id": "-MFdYmYAb5I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "cqwZqXQBb9in"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Load and normalize the dataset"
      ],
      "metadata": {
        "id": "Fh7g-N7kcv_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                       train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l1ldXYDc5uv",
        "outputId": "a5787c34-e168-4302-8229-3ee20ce0a0cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 106715309.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Build the neural network"
      ],
      "metadata": {
        "id": "4JFTgyH4erSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "0UbdnLj7e0KS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Define a Loss function and optimizer"
      ],
      "metadata": {
        "id": "9U9P048QgXaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "b9ctAwlJgdKC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Zero the gradients while training the network\n",
        "\n",
        "We have to loop over our data iterator, and feed the inputs to the network and optimize.\n",
        "\n",
        "We zero out the gradients for each entity data. So we don't track any unnecessary information when train the neural network"
      ],
      "metadata": {
        "id": "oUXeofI5g8r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2): # Loop over the dataset multiple times\n",
        "  running_loss= 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "\n",
        "    #zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss / 2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZFdhXRdhhiJ",
        "outputId": "91b4e3a4-85b7-4c42-846b-012f8fb3b10b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.165\n",
            "[1,  4000] loss: 1.829\n",
            "[1,  6000] loss: 1.630\n",
            "[1,  8000] loss: 1.551\n",
            "[1, 10000] loss: 1.507\n",
            "[1, 12000] loss: 1.446\n",
            "[2,  2000] loss: 1.393\n",
            "[2,  4000] loss: 1.360\n",
            "[2,  6000] loss: 1.330\n",
            "[2,  8000] loss: 1.333\n",
            "[2, 10000] loss: 1.307\n",
            "[2, 12000] loss: 1.288\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use model.zero_grad(). This is the same as using optimizer.zero_grad() as long as all your model parameters are in that optimizer."
      ],
      "metadata": {
        "id": "OYh5G8VljKWh"
      }
    }
  ]
}