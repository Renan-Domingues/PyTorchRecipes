{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqQnBt8jXDtVkv7eiTcUlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renan-Domingues/PyTorchRecipes/blob/main/SavingAndLoadingCheckpoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and loading a general checkpoint in PyTorch\n",
        "\n",
        "It's important to save the optimizer\n",
        "it will save the epoch we left off, the last recorded training loss and more"
      ],
      "metadata": {
        "id": "hRJUHiX4HCLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "we must organize them in dictionary and use torch.salve().\n",
        "is convention to save using .tar file extention.\n",
        "To load we will use torch.load()"
      ],
      "metadata": {
        "id": "orsGVlanHhtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps\n",
        "\n",
        "1. Import all necessary libraries for loading our data\n",
        "2. Define and initialize the neural network\n",
        "3. Initialize the optimizer\n",
        "4. Save the general checkpoint\n",
        "5. Load the general checkpoint\n"
      ],
      "metadata": {
        "id": "CPQ3OgmUIHY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import the libaries"
      ],
      "metadata": {
        "id": "s4fK69aAIjAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "bf8Mn--SIX6j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and initialize the neural network\n",
        "\n",
        "The same as I been using to others examples"
      ],
      "metadata": {
        "id": "plAhiWx_Il87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33O-FTCoIxdn",
        "outputId": "71ffa753-c3c2-4a10-8f59-57646cd9ba89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the optimer\n",
        "\n",
        "using SGD with momentum"
      ],
      "metadata": {
        "id": "kKKxESJqKB7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "GMSu8EhTKRJg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the general checkpoint"
      ],
      "metadata": {
        "id": "QupAhUBOKcD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all relevant information and build my dictionary\n",
        "\n",
        "# addicional information\n",
        "EPOCH = 5\n",
        "PATH = \"model.pt\"\n",
        "LOSS = 0.4\n",
        "\n",
        "torch.save({\n",
        "    'epoch': EPOCH,\n",
        "    'model_state_dict': net.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': LOSS,\n",
        "}, PATH)"
      ],
      "metadata": {
        "id": "5o989xb1KjFw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the general checkpoint\n",
        "\n",
        "First initialize the model and optimizer, then load the dictionary locally."
      ],
      "metadata": {
        "id": "6-bXemawLQFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# or model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKhNyC8NLeik",
        "outputId": "0f99f522-1c19-4336-b131-44c9bb485c0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
        "\n",
        "If I wish to resuming training, call model.train() to ensure these layers are in training mode."
      ],
      "metadata": {
        "id": "ypVNWyZ6Md0Q"
      }
    }
  ]
}