{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfHaHJCMrhYWorbYIx6Oqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renan-Domingues/PyTorchRecipes/blob/main/WarmstartingModelWithDifferentParameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Warmstarting model using parameters from a different model in PyTorch\n",
        "\n",
        "Partial loading a model or loading a partial model are common scenarios when transfer learning or training a new complex model.\n",
        "\n",
        "Levearing trained parameters will help to warmstart the training process and hopefully help the model to converge much faster than training from scratch"
      ],
      "metadata": {
        "id": "YBpKUW9NPskL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "Whether we are loading from partial state_dict (missing some keys) or loading a state_dict with more keys than the model that we are looking into, we can set the strict argumento to False in the load_state_dict() to ignore non-maching keys.\n",
        "\n",
        "We will experiment with warmstarting a model using parameters of a diferent model."
      ],
      "metadata": {
        "id": "ZXIEdoJGQgUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps\n",
        "\n",
        "1. Import all necessary libraries for loading our data\n",
        "2. Define and initialize the neural network A and B\n",
        "3. Save model A\n",
        "4. Load into model B\n"
      ],
      "metadata": {
        "id": "ZmnvyRdLRWIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import necessary libraries for loading our data"
      ],
      "metadata": {
        "id": "sNaDAixcRi_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "6va6ecf0Rk5S"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Define and initialize the neural network A and B\n",
        "\n",
        "We will create two neural networks for sake of loading one parameter of type A into type B."
      ],
      "metadata": {
        "id": "HZxYbjsiRwQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetA(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NetA, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "netA = NetA()\n",
        "\n",
        "class NetB(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NetB, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "netB = NetB()"
      ],
      "metadata": {
        "id": "SNXesRsqR4fB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Save model A\n"
      ],
      "metadata": {
        "id": "KjHUlGh_U6ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# especify a path to save to\n",
        "PATH = \"model.pt\"\n",
        "\n",
        "torch.save(netA.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "vsaP63TJVAOC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Load into model B\n",
        "\n",
        "If you want to load parameters from one layer to another, but some keys do not match, simply change the name of the parameter keys in the state_dict that you are loading to match the keys in the model that you are loading into."
      ],
      "metadata": {
        "id": "wruMcUgZVTtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netB.load_state_dict(torch.load(PATH), strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHVg0PyVVtBx",
        "outputId": "7c974e15-4116-4697-86ed-726d9510278e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}